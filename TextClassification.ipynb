{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Text classification tools\n",
    "\n",
    "Links:\n",
    "\n",
    "* [https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge](https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge)\n",
    "\n",
    "* [https://www.analyticsvidhya.com/blog/2017/08/introduction-to-multi-label-classification/](https://www.analyticsvidhya.com/blog/2017/08/introduction-to-multi-label-classification/)\n",
    "\n",
    "* [https://towardsdatascience.com/machine-learning-nlp-text-classification-using-scikit-learn-python-and-nltk-c52b92a7c73a](https://towardsdatascience.com/machine-learning-nlp-text-classification-using-scikit-learn-python-and-nltk-c52b92a7c73a)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# metrics\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, log_loss\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "\n",
    "# feature engineering\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# multilabel\n",
    "from skmultilearn.problem_transform import BinaryRelevance, ClassifierChain\n",
    "\n",
    "# classifiers\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "pd.set_option(\"display.width\", 150)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train (159571,)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(\"~/Downloads/toxic-comment/train.csv\", index_col=0)\n",
    "test = pd.read_csv(\"~/Downloads/toxic-comment/test.csv\", index_col=0)\n",
    "\n",
    "X, y = train.iloc[:, 0], train.iloc[:, 1:]\n",
    "print(\"Train\", X.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train (159571, 189460)\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(stop_words=\"english\")\n",
    "\n",
    "X_tfidf = vectorizer.fit_transform(X)\n",
    "print(\"Train\", X_tfidf.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(119678, 189460) \n",
      "\n",
      "                  toxic  severe_toxic  obscene  threat  insult  identity_hate\n",
      "id                                                                           \n",
      "fd38c4eb084bd763      0             0        0       0       0              0\n",
      "9a5a4eb29c89ad1d      0             0        0       0       0              0\n",
      "539857e6234a0678      0             0        0       0       0              0\n",
      "52573c72a52d15cf      0             0        0       0       0              0\n",
      "6eb207a2f918269d      0             0        0       0       0              0\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_tfidf, y)\n",
    "\n",
    "print(X_train.shape, \"\\n\")\n",
    "print(y_train.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification and tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize multi-label classifier\n",
    "\n",
    "alg = SVC(probability=True)\n",
    "# alg = GaussianNB()\n",
    "# alg = MultinomialNB()\n",
    "# alg = SGDClassifier(loss=\"log\", max_iter=1000, tol=1e-3)\n",
    "\n",
    "# classifier = BinaryRelevance(alg)\n",
    "classifier = ClassifierChain(alg)\n",
    "\n",
    "QTD_train = 2000\n",
    "QTD_test = 1000\n",
    "\n",
    "# train\n",
    "classifier.fit(X_train[:QTD_train], y_train[:QTD_train])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58\n"
     ]
    }
   ],
   "source": [
    "predictions = classifier.predict(X_test[:QTD_test])\n",
    "print(predictions.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.91\n",
      "Precision 0.864478114478\n",
      "Recall 0.242424242424\n",
      "Log loss 0.589424088198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy\", accuracy_score(y_test[:QTD_test], predictions.toarray()))\n",
    "print(\"Precision\", precision_score(y_test[:QTD_test], predictions.toarray(), average=\"weighted\"))\n",
    "print(\"Recall\", recall_score(y_test[:QTD_test], predictions.toarray(), average=\"weighted\"))\n",
    "print(\"Log loss\", log_loss(y_test[:QTD_test], predictions.toarray()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "toxic            0.924\n",
       "severe_toxic     0.992\n",
       "obscene          0.965\n",
       "threat           0.999\n",
       "insult           0.967\n",
       "identity_hate    0.993\n",
       "dtype: float64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(np.equal(y_test[:QTD_test], predictions.toarray()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline: 0.899% (0.004%)\n"
     ]
    }
   ],
   "source": [
    "results = cross_val_score(classifier, X_tfidf[:QTD_train], y[:QTD_train], cv=KFold(n_splits=2, shuffle=True))\n",
    "print(\"Baseline: %.3f%% (%.3f%%)\" % (results.mean(), results.std()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test (153164, 189460)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ClassifierChain(classifier=LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0),\n",
       "        require_dense=[True, True])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_tfidf = vectorizer.transform(test.iloc[:, 0])\n",
    "print(\"Test\", X_test_tfidf.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'LinearSVC' object has no attribute 'predict_proba'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-a886dbeaf9ff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m999\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mtmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_test_tfidf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"%\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/skmultilearn/problem_transform/cc.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    109\u001b[0m                 prediction, sparse_format='csc', enforce_sparse=True)\n\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m             prediction_proba = self.classifiers[label].predict_proba(\n\u001b[0m\u001b[1;32m    112\u001b[0m                 self.ensure_input_format(X_extended))\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'LinearSVC' object has no attribute 'predict_proba'"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "subm = pd.DataFrame(columns=y_train.columns)\n",
    "subm.index.names = [\"id\"]\n",
    "\n",
    "for i in range(1000, test.shape[0]+999, 1000):\n",
    "    tmp = X_test_tfidf[i-1000:min(i, test.shape[0])]\n",
    "    predictions = classifier.predict_proba(tmp)\n",
    "    print(i*100/test.shape[0], \"%\")\n",
    "\n",
    "    tmp = pd.DataFrame(predictions.toarray(), columns=y_train.columns)\n",
    "    tmp = tmp.set_index(test[i-1000:min(i, test.shape[0])].index)\n",
    "    subm = subm.append(tmp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(153164, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>00001cee341fdb12</th>\n",
       "      <td>0.036834</td>\n",
       "      <td>0.001252</td>\n",
       "      <td>0.019624</td>\n",
       "      <td>0.000901</td>\n",
       "      <td>0.012901</td>\n",
       "      <td>0.005071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0000247867823ef7</th>\n",
       "      <td>0.103590</td>\n",
       "      <td>0.001278</td>\n",
       "      <td>0.062008</td>\n",
       "      <td>0.000920</td>\n",
       "      <td>0.024996</td>\n",
       "      <td>0.005153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00013b17ad220c46</th>\n",
       "      <td>0.067245</td>\n",
       "      <td>0.001296</td>\n",
       "      <td>0.034660</td>\n",
       "      <td>0.000934</td>\n",
       "      <td>0.020561</td>\n",
       "      <td>0.005224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00017563c3f7919a</th>\n",
       "      <td>0.037289</td>\n",
       "      <td>0.001146</td>\n",
       "      <td>0.036835</td>\n",
       "      <td>0.000887</td>\n",
       "      <td>0.008607</td>\n",
       "      <td>0.005713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00017695ad8997eb</th>\n",
       "      <td>0.099386</td>\n",
       "      <td>0.001374</td>\n",
       "      <td>0.074929</td>\n",
       "      <td>0.000880</td>\n",
       "      <td>0.046996</td>\n",
       "      <td>0.004783</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     toxic  severe_toxic   obscene    threat    insult  identity_hate\n",
       "id                                                                                   \n",
       "00001cee341fdb12  0.036834      0.001252  0.019624  0.000901  0.012901       0.005071\n",
       "0000247867823ef7  0.103590      0.001278  0.062008  0.000920  0.024996       0.005153\n",
       "00013b17ad220c46  0.067245      0.001296  0.034660  0.000934  0.020561       0.005224\n",
       "00017563c3f7919a  0.037289      0.001146  0.036835  0.000887  0.008607       0.005713\n",
       "00017695ad8997eb  0.099386      0.001374  0.074929  0.000880  0.046996       0.004783"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tmp = X_tfidf[153000:]\n",
    "# predictions = classifier.predict_proba(tmp)\n",
    "# print(predictions.shape)\n",
    "\n",
    "# tmp = pd.DataFrame(predictions.toarray(), columns=y_train.columns).set_index(X_test[153000:].index)\n",
    "# subm = subm.append(tmp)\n",
    "\n",
    "print(subm.shape)\n",
    "subm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "subm.to_csv(\"subm.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
